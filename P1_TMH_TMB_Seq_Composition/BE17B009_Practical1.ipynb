{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AA composition calculation\n",
    "def AA_freq(peptide):\n",
    "          \n",
    "    aa_freq = {'A':0, 'C':0, 'D':0, 'E':0, 'F':0, 'G':0, 'H':0, 'I':0, 'K':0, 'L':0, 'M':0, 'N' :0, 'P':0, 'Q':0, 'R':0, 'S':0, 'T':0, 'V':0, \n",
    "               'W':0, 'Y':0}\n",
    "    for i in peptide: \n",
    "        aa_freq[i] += 1\n",
    "    for i in aa_freq:\n",
    "        aa_freq[i]= aa_freq[i]/len(peptide)*100\n",
    "      \n",
    "    print (\"{:<8} {:<8}\".format('AA','% composition'))\n",
    "    for key, value in aa_freq.items():\n",
    "       print (\"{:<8} {:<8}\".format(key, value))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse fasta file\n",
    "def read_fasta(fp):\n",
    "        name, seq = None, []\n",
    "        for line in fp:\n",
    "            line = line.rstrip()\n",
    "            if line.startswith(\">\"):\n",
    "                if name: yield (name, ''.join(seq))\n",
    "                name, seq = line, []\n",
    "            else:\n",
    "                seq.append(line)\n",
    "        if name: yield (name, ''.join(seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AA       % composition\n",
      "A        8.511452289914551\n",
      "C        1.2848910635837396\n",
      "D        4.017485474057634\n",
      "E        4.798288840728721\n",
      "F        5.627783731379296\n",
      "G        7.145481143989967\n",
      "H        2.2480702723030004\n",
      "I        6.783772680142336\n",
      "K        4.499618510604535\n",
      "L        11.628144570351644\n",
      "M        2.861061779544778\n",
      "N        3.6514295527118352\n",
      "P        4.428972326259296\n",
      "Q        3.336673629844426\n",
      "R        4.39093207315032\n",
      "S        6.678346835811746\n",
      "T        5.423235856090462\n",
      "V        7.465888761604994\n",
      "W        1.80875969211306\n",
      "Y        3.4097109158136596\n"
     ]
    }
   ],
   "source": [
    "#Q5 AA composition for overall TMH\n",
    "\n",
    "fasta_file = \"alphanr40.txt\"\n",
    "identifiersTMH =[]\n",
    "sequencesTMH= []\n",
    "\n",
    "with open(fasta_file) as fp:\n",
    "    for name, seq in read_fasta(fp):\n",
    "        seq= seq.replace(\" \", \"\")   #Remove space\n",
    "        seq= seq.replace(\"U\", \"\")   #Remove 'U'\n",
    "                  \n",
    "        identifiersTMH.append(name)\n",
    "        sequencesTMH.append(seq)\n",
    "        \n",
    "TMH_overall = ''.join(map(str, sequencesTMH))\n",
    "AA_freq(TMH_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AA       % composition\n",
      "A        7.965135223199739\n",
      "C        0.4024112088628217\n",
      "D        6.7595307917888565\n",
      "E        4.617139133268165\n",
      "F        4.221244705115673\n",
      "G        9.501466275659824\n",
      "H        1.9582926034538939\n",
      "I        4.11208862821766\n",
      "K        4.622026718800912\n",
      "L        7.893450635386119\n",
      "M        1.5868361029651352\n",
      "N        6.133919843597263\n",
      "P        3.704789833822092\n",
      "Q        4.351580319322255\n",
      "R        5.047246660149886\n",
      "S        7.642554578038449\n",
      "T        6.712284131638971\n",
      "V        6.112740306288694\n",
      "W        1.6568914956011729\n",
      "Y        4.998370804822418\n"
     ]
    }
   ],
   "source": [
    "#Q5 AA composition for overall TMB\n",
    "\n",
    "fasta_file = \"betanr40.txt\"\n",
    "identifiersTMB =[]\n",
    "sequencesTMB= []\n",
    "\n",
    "with open(fasta_file) as fp:\n",
    "    for name, seq in read_fasta(fp):\n",
    "        seq= seq.replace(\" \", \"\")   #Remove space\n",
    "        seq= seq.replace(\"U\", \"\")   #Remove 'U'\n",
    "                  \n",
    "        identifiersTMB.append(name)\n",
    "        sequencesTMB.append(seq)\n",
    "        \n",
    "TMB_overall = ''.join(map(str, sequencesTMB))\n",
    "AA_freq(TMB_overall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AA composition\n",
    "def AA_freq(peptide):\n",
    "    aa_freq = {'A':0, 'C':0, 'D':0, 'E':0, 'F':0, 'G':0, 'H':0, 'I':0, 'K':0,\n",
    "               'L':0, 'M':0, 'N' :0, 'P':0, 'Q':0, 'R':0, 'S':0, 'T':0, 'V':0, \n",
    "               'W':0, 'Y':0}\n",
    "    for i in peptide: \n",
    "        aa_freq[i] += 1\n",
    "    for i in aa_freq:\n",
    "        aa_freq[i]= aa_freq[i]/len(peptide)*100\n",
    "      \n",
    "    return aa_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6(a) Composition for each sequence in TMH: Filename: ‘TMHseq_composition.csv’\n",
    "\n",
    "import csv\n",
    "# name of csv file  \n",
    "filenameA = \"TMHseq_composition.csv\"\n",
    "\n",
    "# field names  \n",
    "fields = ['Seq','A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q',\n",
    " 'R', 'S', 'T', 'V', 'W', 'Y' ]\n",
    "\n",
    "TMHdict=[]\n",
    "\n",
    "for i in range(0, len(sequencesTMH)):\n",
    "    seq= sequencesTMH[i]\n",
    "    aa_freq_peptide= AA_freq(seq)\n",
    "    aa_freq_peptide['Seq']= identifiersTMH[i]\n",
    "    TMHdict.append(aa_freq_peptide)\n",
    "    \n",
    "    \n",
    "with open(filenameA, 'w') as csvfile:  \n",
    "    writer = csv.DictWriter(csvfile, fieldnames = fields)  \n",
    "    writer.writeheader()  # field names \n",
    "    writer.writerows(TMHdict) # data rows\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6 (b)(c)(d)(e)(f)\n",
    "TMHcomp = {'A':8.511, 'C':1.285, 'D': 4.017, 'E':4.798, 'F':5.628, 'G':7.145, 'H':2.248, \n",
    "           'I':6.784, 'K':4.499, 'L':11.628, 'M':2.861, 'N' :3.651, 'P':4.429, 'Q':3.337, \n",
    "           'R':4.391, 'S':6.678, 'T':5.423, 'V':7.465, 'W':1.809, 'Y':3.409}\n",
    "\n",
    "TMBcomp = {'A':7.965, 'C':0.402, 'D':6.759, 'E':4.617, 'F':4.221, 'G':9.501, 'H':1.958, \n",
    "           'I':4.112, 'K':4.622, 'L':7.893, 'M':1.587, 'N' :6.134, 'P':3.705, 'Q':4.352, \n",
    "           'R':5.047, 'S':7.642, 'T':6.712, 'V':6.113, 'W':1.657, 'Y':4.998}\n",
    "\n",
    "TruePositives = 0\n",
    "FalseNegatives = 0\n",
    "TrueNegatives = 0\n",
    "FalsePositives = 0\n",
    "\n",
    "for seq_comp in TMHdict:\n",
    "    dev_A=0\n",
    "    dev_B=0\n",
    "    \n",
    "    for i in TMHcomp.keys():\n",
    "        dev_A = dev_A + abs(seq_comp[i]- TMHcomp[i])\n",
    "        dev_B = dev_B + abs(seq_comp[i]- TMBcomp[i])\n",
    "        \n",
    "    if dev_A < dev_B:\n",
    "        TruePositives = TruePositives + 1\n",
    "    else:\n",
    "        FalseNegatives = FalseNegatives + 1   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1058\n",
      "96\n"
     ]
    }
   ],
   "source": [
    "print(TruePositives)\n",
    "print(FalseNegatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7 Composition for each sequence in TMB: Filename: ‘TMBseq_composition.csv’\n",
    "\n",
    "filenameB = \"TMBseq_composition.csv\"\n",
    "# field names  \n",
    "fields = ['Seq','A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y' ]\n",
    "\n",
    "TMBdict=[]\n",
    "\n",
    "for i in range(0, len(sequencesTMB)):\n",
    "    seq= sequencesTMB[i]\n",
    "    aa_freq_peptide= AA_freq(seq)\n",
    "    aa_freq_peptide['Seq']= identifiersTMB[i]\n",
    "    TMBdict.append(aa_freq_peptide)\n",
    "    \n",
    "    \n",
    "with open(filenameB, 'w') as csvfile:  \n",
    "    writer = csv.DictWriter(csvfile, fieldnames = fields)  \n",
    "    writer.writeheader()   # field names \n",
    "    writer.writerows(TMBdict) # data rows  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq_comp in TMBdict:\n",
    "    dev_A=0\n",
    "    dev_B=0\n",
    "    \n",
    "    for i in TMBcomp.keys():\n",
    "        dev_A = dev_A + abs(seq_comp[i]- TMHcomp[i])\n",
    "        dev_B = dev_B + abs(seq_comp[i]- TMBcomp[i])\n",
    "        \n",
    "    if dev_A > dev_B:\n",
    "        TrueNegatives = TrueNegatives + 1\n",
    "    else:\n",
    "        FalsePositives = FalsePositives + 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print(TrueNegatives)\n",
    "print(FalsePositives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity using 100% dataset as training=  0.9168110918544194\n",
      "Specificity using 100% dataset as training=  0.9097744360902256\n",
      "Accuracy using 100% dataset as training=  0.916083916083916\n"
     ]
    }
   ],
   "source": [
    "# Using 100% Non-redundant dataset as training \n",
    "TP = TruePositives\n",
    "FN = FalseNegatives\n",
    "TN = TrueNegatives\n",
    "FP= FalsePositives\n",
    "\n",
    "Sensitivity = TP/(TP+FN)\n",
    "Specificity = TN/(TN+FP)\n",
    "Accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "\n",
    "print('Sensitivity using 100% dataset as training= ', Sensitivity)\n",
    "print('Specificity using 100% dataset as training= ', Specificity)\n",
    "print('Accuracy using 100% dataset as training= ', Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046\n",
      "108\n"
     ]
    }
   ],
   "source": [
    "# Include a deviation (TMH + 0.5) to estimate the sensitivity, specificity and accuracy\n",
    "TruePositives = 0\n",
    "FalseNegatives = 0\n",
    "\n",
    "for seq_comp in TMHdict:\n",
    "    dev_A=0\n",
    "    dev_B=0\n",
    "    \n",
    "    for i in TMHcomp.keys():\n",
    "        dev_A = dev_A + abs(seq_comp[i]- TMHcomp[i]) \n",
    "        dev_B = dev_B + abs(seq_comp[i]- TMBcomp[i])\n",
    "        \n",
    "    if dev_A + 0.5 < dev_B:      # Deviation (TMH + 0.5) \n",
    "        TruePositives = TruePositives + 1\n",
    "    else:\n",
    "        FalseNegatives = FalseNegatives + 1\n",
    "\n",
    "print(TruePositives)\n",
    "print(FalseNegatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity using 100% dataset as training and deviation 0.5 to TMH=  0.9064124783362218\n",
      "Specificity using 100% dataset as training and deviation 0.5 to TMH =  0.9097744360902256\n",
      "Accuracy using 100% dataset as training and deviation 0.5 to TMH=  0.9067599067599068\n"
     ]
    }
   ],
   "source": [
    "# Include a deviation (TMH + 0.5) to estimate the sensitivity, specificity and accuracy\n",
    "TP = TruePositives\n",
    "FN = FalseNegatives\n",
    "TN = TrueNegatives\n",
    "FP= FalsePositives\n",
    "\n",
    "Sensitivity = TP/(TP+FN)\n",
    "Specificity = TN/(TN+FP)\n",
    "Accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "\n",
    "print('Sensitivity using 100% dataset as training and deviation 0.5 to TMH= ', Sensitivity)\n",
    "print('Specificity using 100% dataset as training and deviation 0.5 to TMH = ', Specificity)\n",
    "print('Accuracy using 100% dataset as training and deviation 0.5 to TMH= ', Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse all non-reduntant TMH        \n",
    "fasta_file = \"alphanr40.txt\"\n",
    "identifiersTMH =[]  \n",
    "sequencesTMH= []    \n",
    "\n",
    "with open(fasta_file) as fp:\n",
    "    for name, seq in read_fasta(fp):\n",
    "        seq= seq.replace(\" \", \"\")   #Remove space\n",
    "        seq= seq.replace(\"U\", \"\")   #Remove 'U'\n",
    "                  \n",
    "        identifiersTMH.append(name)\n",
    "        sequencesTMH.append(seq)   \n",
    "\n",
    "# Parse all non-reduntant TMB\n",
    "fasta_file = \"betanr40.txt\"\n",
    "identifiersTMB =[]\n",
    "sequencesTMB= []\n",
    "\n",
    "with open(fasta_file) as fp:\n",
    "    for name, seq in read_fasta(fp):\n",
    "        seq= seq.replace(\" \", \"\")   #Remove space\n",
    "        seq= seq.replace(\"U\", \"\")   #Remove 'U'\n",
    "                  \n",
    "        identifiersTMB.append(name)\n",
    "        sequencesTMB.append(seq)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity using 70% dataset as training and 30% dataset as test=  0.9048991354466859\n",
      "Specificity using 70% dataset as training and 30% dataset as test=  0.9\n",
      "Accuracy using 70% dataset as training and 30% dataset as test =  0.9043927648578811\n"
     ]
    }
   ],
   "source": [
    "# Considering 70% of TMH and 70% of TMB to compute the composition\n",
    "# using 70% dataset as training and 30% dataset as test\n",
    "import sklearn       \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainTMH70, testTMH70 = sklearn.model_selection.train_test_split(sequencesTMH, train_size=0.7, test_size=0.3, random_state=9)\n",
    "trainTMB70, testTMB70 = sklearn.model_selection.train_test_split(sequencesTMB, train_size=0.7, test_size=0.3, random_state=9)\n",
    "\n",
    "trainTMH70_overall = ''.join(map(str, trainTMH70))\n",
    "trainTMH70comp= AA_freq(trainTMH70_overall)        #TMH comp using 70% Training\n",
    "\n",
    "trainTMB70_overall = ''.join(map(str, trainTMB70))\n",
    "trainTMB70comp= AA_freq(trainTMB70_overall)        #TMB comp using 70% Training\n",
    "\n",
    "TP70 = 0\n",
    "FN70 = 0\n",
    "TN70 = 0\n",
    "FP70 = 0\n",
    "\n",
    "for seq in testTMH70:\n",
    "    aa_comp_test= AA_freq(seq)\n",
    "    dev_A70=0\n",
    "    dev_B70=0\n",
    "    \n",
    "    for i in trainTMH70comp.keys():\n",
    "        dev_A70 = dev_A70 + abs(aa_comp_test[i]- trainTMH70comp[i])\n",
    "        dev_B70 = dev_B70 + abs(aa_comp_test[i]- trainTMB70comp[i])\n",
    "        \n",
    "    if dev_A70 < dev_B70:\n",
    "        TP70 = TP70 + 1\n",
    "    else:\n",
    "        FN70 = FN70 + 1   \n",
    "\n",
    "for seq in testTMB70:\n",
    "    aa_comp_test= AA_freq(seq)\n",
    "    dev_A70=0\n",
    "    dev_B70=0\n",
    "    \n",
    "    for i in trainTMB70comp.keys():\n",
    "        dev_A70 = dev_A70 + abs(aa_comp_test[i]- trainTMH70comp[i])\n",
    "        dev_B70 = dev_B70 + abs(aa_comp_test[i]- trainTMB70comp[i])\n",
    "        \n",
    "    if dev_A70 > dev_B70:\n",
    "        TN70 = TN70 + 1\n",
    "    else:\n",
    "        FP70 = FP70 + 1\n",
    "    \n",
    "Sensitivity70 = TP70/(TP70+FN70)\n",
    "Specificity70 = TN70/(TN70+FP70)\n",
    "Accuracy70 = (TP70+TN70)/(TP70+TN70+FP70+FN70)\n",
    "\n",
    "print('Sensitivity using 70% dataset as training and 30% dataset as test= ', Sensitivity70)\n",
    "print('Specificity using 70% dataset as training and 30% dataset as test= ', Specificity70)\n",
    "print('Accuracy using 70% dataset as training and 30% dataset as test = ', Accuracy70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity using 60% dataset as training and 40% dataset as test=  0.9047619047619048\n",
      "Specificity using 60% dataset as training and 40% dataset as test=  0.9259259259259259\n",
      "Accuracy using 60% dataset as training and 40% dataset as test =  0.9069767441860465\n"
     ]
    }
   ],
   "source": [
    "# Considering 60% of TMH and 60% of TMB to compute the composition\n",
    "# using 60% dataset as training and 40% dataset as test\n",
    "import sklearn       \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainTMH60, testTMH60 = sklearn.model_selection.train_test_split(sequencesTMH, train_size=0.6, test_size=0.4, random_state=9)\n",
    "trainTMB60, testTMB60 = sklearn.model_selection.train_test_split(sequencesTMB, train_size=0.6, test_size=0.4, random_state=9)\n",
    "\n",
    "trainTMH60_overall = ''.join(map(str, trainTMH60))\n",
    "trainTMH60comp= AA_freq(trainTMH60_overall)        #TMH comp using 60% Training\n",
    "\n",
    "trainTMB60_overall = ''.join(map(str, trainTMB60))\n",
    "trainTMB60comp= AA_freq(trainTMB60_overall)        #TMB comp using 60% Training\n",
    "\n",
    "TP60 = 0\n",
    "FN60 = 0\n",
    "TN60 = 0\n",
    "FP60 = 0\n",
    "\n",
    "for seq in testTMH60:\n",
    "    aa_comp_test= AA_freq(seq)\n",
    "    dev_A60=0\n",
    "    dev_B60=0\n",
    "    \n",
    "    for i in trainTMH60comp.keys():\n",
    "        dev_A60 = dev_A60 + abs(aa_comp_test[i]- trainTMH60comp[i])\n",
    "        dev_B60 = dev_B60 + abs(aa_comp_test[i]- trainTMB60comp[i])\n",
    "        \n",
    "    if dev_A60 < dev_B60:\n",
    "        TP60 = TP60 + 1\n",
    "    else:\n",
    "        FN60 = FN60 + 1   \n",
    "\n",
    "for seq in testTMB60:\n",
    "    aa_comp_test= AA_freq(seq)\n",
    "    dev_A60=0\n",
    "    dev_B60=0\n",
    "    \n",
    "    for i in trainTMB60comp.keys():\n",
    "        dev_A60 = dev_A60 + abs(aa_comp_test[i]- trainTMH60comp[i])\n",
    "        dev_B60 = dev_B60 + abs(aa_comp_test[i]- trainTMB60comp[i])\n",
    "        \n",
    "    if dev_A60 > dev_B60:\n",
    "        TN60 = TN60 + 1\n",
    "    else:\n",
    "        FP60 = FP60 + 1\n",
    "    \n",
    "Sensitivity60 = TP60/(TP60+FN60)\n",
    "Specificity60 = TN60/(TN60+FP60)\n",
    "Accuracy60 = (TP60+TN60)/(TP60+TN60+FP60+FN60)\n",
    "\n",
    "print('Sensitivity using 60% dataset as training and 40% dataset as test= ', Sensitivity60)\n",
    "print('Specificity using 60% dataset as training and 40% dataset as test= ', Specificity60)\n",
    "print('Accuracy using 60% dataset as training and 40% dataset as test = ', Accuracy60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity using 50% dataset as training and 50% dataset as test =  0.9046793760831889\n",
      "Specificity using 50% dataset as training and 50% dataset as test =  0.9104477611940298\n",
      "Accuracy using 50% dataset as training and 50% dataset as test=  0.90527950310559\n"
     ]
    }
   ],
   "source": [
    "# Considering 50% of TMH and 50% of TMB to compute the composition\n",
    "# using 50% dataset as training and 50% dataset as test\n",
    "import sklearn       \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainTMH50, testTMH50 = sklearn.model_selection.train_test_split(sequencesTMH, train_size=0.5, test_size=0.5, random_state=9)\n",
    "trainTMB50, testTMB50 = sklearn.model_selection.train_test_split(sequencesTMB, train_size=0.5, test_size=0.5, random_state=9)\n",
    "\n",
    "trainTMH50_overall = ''.join(map(str, trainTMH50))\n",
    "trainTMH50comp= AA_freq(trainTMH50_overall)        #TMH comp using 50% Training\n",
    "\n",
    "trainTMB50_overall = ''.join(map(str, trainTMB50))\n",
    "trainTMB50comp= AA_freq(trainTMB50_overall)        #TMB comp using 50% Training\n",
    "\n",
    "TP50 = 0\n",
    "FN50 = 0\n",
    "TN50 = 0\n",
    "FP50 = 0\n",
    "\n",
    "for seq in testTMH50:\n",
    "    aa_comp_test= AA_freq(seq)\n",
    "    dev_A50=0\n",
    "    dev_B50=0\n",
    "    \n",
    "    for i in trainTMH50comp.keys():\n",
    "        dev_A50 = dev_A50 + abs(aa_comp_test[i]- trainTMH50comp[i])\n",
    "        dev_B50 = dev_B50 + abs(aa_comp_test[i]- trainTMB50comp[i])\n",
    "        \n",
    "    if dev_A50 < dev_B50:\n",
    "        TP50 = TP50 + 1\n",
    "    else:\n",
    "        FN50 = FN50 + 1   \n",
    "\n",
    "for seq in testTMB50:\n",
    "    aa_comp_test= AA_freq(seq)\n",
    "    dev_A50=0\n",
    "    dev_B50=0\n",
    "    \n",
    "    for i in trainTMB50comp.keys():\n",
    "        dev_A50 = dev_A50 + abs(aa_comp_test[i]- trainTMH50comp[i])\n",
    "        dev_B50 = dev_B50 + abs(aa_comp_test[i]- trainTMB50comp[i])\n",
    "        \n",
    "    if dev_A50 > dev_B50:\n",
    "        TN50 = TN50 + 1\n",
    "    else:\n",
    "        FP50 = FP50 + 1\n",
    "    \n",
    "Sensitivity50 = TP50/(TP50+FN50)\n",
    "Specificity50 = TN50/(TN50+FP50)\n",
    "Accuracy50 = (TP50+TN50)/(TP50+TN50+FP50+FN50)\n",
    "\n",
    "print('Sensitivity using 50% dataset as training and 50% dataset as test = ', Sensitivity50)\n",
    "print('Specificity using 50% dataset as training and 50% dataset as test = ', Specificity50)\n",
    "print('Accuracy using 50% dataset as training and 50% dataset as test= ', Accuracy50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity using 40% dataset as training and 60% dataset as test=  0.8961038961038961\n",
      "Specificity using 40% dataset as training and 60% dataset as test=  0.925\n",
      "Accuracy using 40% dataset as training and 60% dataset as test =  0.8990944372574385\n"
     ]
    }
   ],
   "source": [
    "# Considering 40% of TMH and 40% of TMB to compute the composition\n",
    "# using 40% dataset as training and 60% dataset as test\n",
    "import sklearn       \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainTMH40, testTMH40 = sklearn.model_selection.train_test_split(sequencesTMH, train_size=0.4, test_size=0.6, random_state=9)\n",
    "trainTMB40, testTMB40 = sklearn.model_selection.train_test_split(sequencesTMB, train_size=0.4, test_size=0.6, random_state=9)\n",
    "\n",
    "trainTMH40_overall = ''.join(map(str, trainTMH40))\n",
    "trainTMH40comp= AA_freq(trainTMH40_overall)        #TMH comp using 40% Training\n",
    "\n",
    "trainTMB40_overall = ''.join(map(str, trainTMB40))\n",
    "trainTMB40comp= AA_freq(trainTMB40_overall)        #TMB comp using 40% Training\n",
    "\n",
    "TP40 = 0\n",
    "FN40 = 0\n",
    "TN40 = 0\n",
    "FP40 = 0\n",
    "\n",
    "for seq in testTMH40:\n",
    "    aa_comp_test= AA_freq(seq)\n",
    "    dev_A40=0\n",
    "    dev_B40=0\n",
    "    \n",
    "    for i in trainTMH40comp.keys():\n",
    "        dev_A40 = dev_A40 + abs(aa_comp_test[i]- trainTMH40comp[i])\n",
    "        dev_B40 = dev_B40 + abs(aa_comp_test[i]- trainTMB40comp[i])\n",
    "        \n",
    "    if dev_A40 < dev_B40:\n",
    "        TP40 = TP40 + 1\n",
    "    else:\n",
    "        FN40 = FN40 + 1   \n",
    "\n",
    "for seq in testTMB40:\n",
    "    aa_comp_test= AA_freq(seq)\n",
    "    dev_A40=0\n",
    "    dev_B40=0\n",
    "    \n",
    "    for i in trainTMB40comp.keys():\n",
    "        dev_A40 = dev_A40 + abs(aa_comp_test[i]- trainTMH40comp[i])\n",
    "        dev_B40 = dev_B40 + abs(aa_comp_test[i]- trainTMB40comp[i])\n",
    "        \n",
    "    if dev_A40 > dev_B40:\n",
    "        TN40 = TN40 + 1\n",
    "    else:\n",
    "        FP40 = FP40 + 1\n",
    "    \n",
    "Sensitivity40 = TP40/(TP40+FN40)\n",
    "Specificity40 = TN40/(TN40+FP40)\n",
    "Accuracy40 = (TP40+TN40)/(TP40+TN40+FP40+FN40)\n",
    "\n",
    "print('Sensitivity using 40% dataset as training and 60% dataset as test= ', Sensitivity40)\n",
    "print('Specificity using 40% dataset as training and 60% dataset as test= ', Specificity40)\n",
    "print('Accuracy using 40% dataset as training and 60% dataset as test = ', Accuracy40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity using 30% dataset as training and 70% dataset as test=  0.8910891089108911\n",
      "Specificity using 30% dataset as training and 70% dataset as test=  0.9148936170212766\n",
      "Accuracy using 30% dataset as training and 70% dataset as test=  0.893569844789357\n"
     ]
    }
   ],
   "source": [
    "# Considering 30% of TMH and 30% of TMB to compute the composition\n",
    "# using 30% dataset as training and 70% dataset as test\n",
    "import sklearn       \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainTMH30, testTMH30 = sklearn.model_selection.train_test_split(sequencesTMH, train_size=0.3, test_size=0.7, random_state=9)\n",
    "trainTMB30, testTMB30 = sklearn.model_selection.train_test_split(sequencesTMB, train_size=0.3, test_size=0.7, random_state=9)\n",
    "\n",
    "trainTMH30_overall = ''.join(map(str, trainTMH30))\n",
    "trainTMH30comp= AA_freq(trainTMH30_overall)        #TMH comp using 30% Training\n",
    "\n",
    "trainTMB30_overall = ''.join(map(str, trainTMB30))\n",
    "trainTMB30comp= AA_freq(trainTMB30_overall)        #TMB comp using 30% Training\n",
    "\n",
    "TP30 = 0\n",
    "FN30 = 0\n",
    "TN30 = 0\n",
    "FP30 = 0\n",
    "\n",
    "for seq in testTMH30:\n",
    "    aa_comp_test= AA_freq(seq)\n",
    "    dev_A30=0\n",
    "    dev_B30=0\n",
    "    \n",
    "    for i in trainTMH30comp.keys():\n",
    "        dev_A30 = dev_A30 + abs(aa_comp_test[i]- trainTMH30comp[i])\n",
    "        dev_B30 = dev_B30 + abs(aa_comp_test[i]- trainTMB30comp[i])\n",
    "        \n",
    "    if dev_A30 < dev_B30:\n",
    "        TP30 = TP30 + 1\n",
    "    else:\n",
    "        FN30 = FN30 + 1   \n",
    "\n",
    "for seq in testTMB30:\n",
    "    aa_comp_test= AA_freq(seq)\n",
    "    dev_A30=0\n",
    "    dev_B30=0\n",
    "    \n",
    "    for i in trainTMB30comp.keys():\n",
    "        dev_A30 = dev_A30 + abs(aa_comp_test[i]- trainTMH30comp[i])\n",
    "        dev_B30 = dev_B30 + abs(aa_comp_test[i]- trainTMB30comp[i])\n",
    "        \n",
    "    if dev_A30 > dev_B30:\n",
    "        TN30 = TN30 + 1\n",
    "    else:\n",
    "        FP30 = FP30 + 1\n",
    "    \n",
    "Sensitivity30 = TP30/(TP30+FN30)\n",
    "Specificity30 = TN30/(TN30+FP30)\n",
    "Accuracy30 = (TP30+TN30)/(TP30+TN30+FP30+FN30)\n",
    "\n",
    "print('Sensitivity using 30% dataset as training and 70% dataset as test= ', Sensitivity30)\n",
    "print('Specificity using 30% dataset as training and 70% dataset as test= ', Specificity30)\n",
    "print('Accuracy using 30% dataset as training and 70% dataset as test= ', Accuracy30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
